{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8TiPWLbPic2",
        "outputId": "f3242671-dae0-4ed9-d172-efd7aa7b554a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-18 13:03:57--  https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar\n",
            "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 811315200 (774M) [application/x-tar]\n",
            "Saving to: ‘wiki_crop.tar’\n",
            "\n",
            "wiki_crop.tar       100%[===================>] 773.73M  25.0MB/s    in 33s     \n",
            "\n",
            "2021-12-18 13:04:30 (23.8 MB/s) - ‘wiki_crop.tar’ saved [811315200/811315200]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsIPK6QnPm-7"
      },
      "outputs": [],
      "source": [
        "!tar -xf wiki_crop.tar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1E0Oiwkod12"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import Input, Model\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, BatchNormalization, Reshape, concatenate, LeakyReLU, Lambda, Activation, UpSampling2D, Dropout\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras_preprocessing import image\n",
        "from scipy.io import loadmat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3x_orTpfhZF"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UD6dX_ksh6Tx"
      },
      "outputs": [],
      "source": [
        "# !tar -xvf \"/content/drive/My Drive/GAN Project/wiki_crop.tar\" -C \"/content/drive/My Drive/GAN Project/DataPoints\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8cxpiEe4bi8"
      },
      "outputs": [],
      "source": [
        "def build_encoder():\n",
        "    \"\"\"\n",
        "    Encoder Network\n",
        "    \"\"\"\n",
        "    input_layer = Input(shape=(64, 64, 3))\n",
        "\n",
        "    # 1st Convolutional Block\n",
        "    enc = Conv2D(filters=32, kernel_size=5, strides=2, padding='same')(input_layer)\n",
        "    enc = LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "    # 2nd Convolutional Block\n",
        "    enc = Conv2D(filters=64, kernel_size=5, strides=2, padding='same')(enc)\n",
        "    enc = BatchNormalization()(enc)\n",
        "    enc = LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "    # 3rd Convolutional Block\n",
        "    enc = Conv2D(filters=128, kernel_size=5, strides=2, padding='same')(enc)\n",
        "    enc = BatchNormalization()(enc)\n",
        "    enc = LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "    # 4th Convolutional Block\n",
        "    enc = Conv2D(filters=256, kernel_size=5, strides=2, padding='same')(enc)\n",
        "    enc = BatchNormalization()(enc)\n",
        "    enc = LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "    # Flatten layer\n",
        "    enc = Flatten()(enc)\n",
        "\n",
        "    # 1st Fully Connected Layer\n",
        "    enc = Dense(4096)(enc)\n",
        "    enc = BatchNormalization()(enc)\n",
        "    enc = LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "    # Second Fully Connected Layer\n",
        "    enc = Dense(100)(enc)\n",
        "\n",
        "    # Create a model\n",
        "    model = Model(inputs=[input_layer], outputs=[enc])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFpXwPE27JAx"
      },
      "outputs": [],
      "source": [
        "def build_generator():\n",
        "    \"\"\"\n",
        "    Create a Generator Model with hyperparameters values defined as follows\n",
        "    \"\"\"\n",
        "    latent_dims = 100\n",
        "    num_classes = 6\n",
        "\n",
        "    input_z_noise = Input(shape=(latent_dims,))\n",
        "    input_label = Input(shape=(num_classes,))\n",
        "\n",
        "    x = concatenate([input_z_noise, input_label])\n",
        "\n",
        "    x = Dense(2048, input_dim=latent_dims + num_classes)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Dense(256 * 8 * 8)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Reshape((8, 8, 256))(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(filters=128, kernel_size=5, padding='same')(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(filters=64, kernel_size=5, padding='same')(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(filters=3, kernel_size=5, padding='same')(x)\n",
        "    x = Activation('tanh')(x)\n",
        "\n",
        "    model = Model(inputs=[input_z_noise, input_label], outputs=[x])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWs-bmBk7kTE"
      },
      "outputs": [],
      "source": [
        "def expand_label_input(x):\n",
        "    x = K.expand_dims(x, axis=1)\n",
        "    x = K.expand_dims(x, axis=1)\n",
        "    x = K.tile(x, [1, 32, 32, 1])\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJcj6A3H8QKC"
      },
      "outputs": [],
      "source": [
        "def build_discriminator():\n",
        "    \"\"\"\n",
        "    Create a Discriminator Model with hyperparameters values defined as follows\n",
        "    \"\"\"\n",
        "    input_shape = (64, 64, 3)\n",
        "    label_shape = (6,)\n",
        "    image_input = Input(shape=input_shape)\n",
        "    label_input = Input(shape=label_shape)\n",
        "\n",
        "    x = Conv2D(64, kernel_size=3, strides=2, padding='same')(image_input)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    label_input1 = Lambda(expand_label_input)(label_input)\n",
        "    x = concatenate([x, label_input1], axis=3)\n",
        "\n",
        "    x = Conv2D(128, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(256, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(512, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=[image_input, label_input], outputs=[x])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ga5bXRsV8Tjc"
      },
      "outputs": [],
      "source": [
        "def build_fr_combined_network(encoder, generator, fr_model):\n",
        "    input_image = Input(shape=(64, 64, 3))\n",
        "    input_label = Input(shape=(6,))\n",
        "\n",
        "    latent0 = encoder(input_image)\n",
        "\n",
        "    gen_images = generator([latent0, input_label])\n",
        "\n",
        "    fr_model.trainable = False\n",
        "\n",
        "    resized_images = Lambda(lambda x: K.resize_images(gen_images, height_factor=2, width_factor=2, data_format='channels_last'))(gen_images)\n",
        "    embeddings = fr_model(resized_images)\n",
        "\n",
        "    model = Model(inputs=[input_image, input_label], outputs=[embeddings])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgBQob1o8WRd"
      },
      "outputs": [],
      "source": [
        "def build_fr_model(input_shape):\n",
        "    resent_model = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=input_shape, pooling='avg')\n",
        "    image_input = resent_model.input\n",
        "    x = resent_model.layers[-1].output\n",
        "    out = Dense(128)(x)\n",
        "    embedder_model = Model(inputs=[image_input], outputs=[out])\n",
        "\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    x = embedder_model(input_layer)\n",
        "    output = Lambda(lambda x: K.l2_normalize(x, axis=-1))(x)\n",
        "\n",
        "    model = Model(inputs=[input_layer], outputs=[output])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1cDCMUM8cFw"
      },
      "outputs": [],
      "source": [
        "def build_image_resizer():\n",
        "    input_layer = Input(shape=(64, 64, 3))\n",
        "\n",
        "    resized_images = Lambda(lambda x: K.resize_images(x, height_factor=3, width_factor=3, data_format='channels_last'))(input_layer)\n",
        "\n",
        "    model = Model(inputs=[input_layer], outputs=[resized_images])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5o6lr7KR8gGo"
      },
      "outputs": [],
      "source": [
        "def calculate_age(taken, dob):\n",
        "    birth = datetime.fromordinal(max(int(dob) - 366, 1))\n",
        "\n",
        "    if birth.month < 7:\n",
        "        return taken - birth.year\n",
        "    else:\n",
        "        return taken - birth.year - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4i3XO3s8gBI"
      },
      "outputs": [],
      "source": [
        "def load_data(wiki_dir, dataset='wiki'):\n",
        "    # Load the wiki.mat file\n",
        "    meta = loadmat(os.path.join(wiki_dir, \"{}.mat\".format(dataset)))\n",
        "\n",
        "    # Load the list of all files\n",
        "    full_path = meta[dataset][0, 0][\"full_path\"][0]\n",
        "\n",
        "    # List of Matlab serial date numbers\n",
        "    dob = meta[dataset][0, 0][\"dob\"][0]\n",
        "\n",
        "    # List of years when photo was taken\n",
        "    photo_taken = meta[dataset][0, 0][\"photo_taken\"][0]  # year\n",
        "\n",
        "    # Calculate age for all dobs\n",
        "    age = [calculate_age(photo_taken[i], dob[i]) for i in range(len(dob))]\n",
        "\n",
        "    # Create a list of tuples containing a pair of an image path and age\n",
        "    images = []\n",
        "    age_list = []\n",
        "    for index, image_path in enumerate(full_path):\n",
        "        images.append(image_path[0])\n",
        "        age_list.append(age[index])\n",
        "\n",
        "    # Return a list of all images and respective age\n",
        "    return images, age_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBYy4JHKYnFT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3FjW4J0_4Dj"
      },
      "outputs": [],
      "source": [
        "# def load_data():#dataset='wiki'):\n",
        "#     meta = scipy.io.loadmat('/content/drive/My Drive/GAN Project/wiki.mat')\n",
        "#     print(meta)\n",
        "#     # Load the list of all files\n",
        "#     dataset = 'wiki'\n",
        "#     full_path = meta[dataset][0, 0][\"full_path\"][0]\n",
        "\n",
        "#     # List of Matlab serial date numbers\n",
        "#     dob = meta[dataset][0, 0][\"dob\"][0]\n",
        "\n",
        "#     # List of years when photo was taken\n",
        "#     photo_taken = meta[dataset][0, 0][\"photo_taken\"][0]  # year\n",
        "\n",
        "#     # Calculate age for all dobs\n",
        "#     age = [calculate_age(photo_taken[i], dob[i]) for i in range(len(dob))]\n",
        "\n",
        "#     # Create a list of tuples containing a pair of an image path and age\n",
        "#     images = []\n",
        "#     age_list = []\n",
        "#     for index, image_path in enumerate(full_path):\n",
        "#         images.append(image_path[0])\n",
        "#         age_list.append(age[index])\n",
        "\n",
        "#     # Return a list of all images and respective age\n",
        "#     print(images)\n",
        "#     print(age_list)\n",
        "#     return images, age_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ab-72FH8kyF"
      },
      "outputs": [],
      "source": [
        "def age_to_category(age_list):\n",
        "    age_list1 = []\n",
        "\n",
        "    for age in age_list:\n",
        "        if 0 < age <= 18:\n",
        "            age_category = 0\n",
        "        elif 18 < age <= 29:\n",
        "            age_category = 1\n",
        "        elif 29 < age <= 39:\n",
        "            age_category = 2\n",
        "        elif 39 < age <= 49:\n",
        "            age_category = 3\n",
        "        elif 49 < age <= 59:\n",
        "            age_category = 4\n",
        "        elif age >= 60:\n",
        "            age_category = 5\n",
        "\n",
        "        age_list1.append(age_category)\n",
        "\n",
        "    return age_list1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Po3w--mG8nIB"
      },
      "outputs": [],
      "source": [
        "def load_images(data_dir, image_paths, image_shape):\n",
        "    images = None\n",
        "    j=0\n",
        "    for i, image_path in enumerate(image_paths):\n",
        "        print()\n",
        "        j+=1\n",
        "        # print(j)\n",
        "        # if j>10000:\n",
        "        #   break\n",
        "        try:\n",
        "            # Load image\n",
        "            loaded_image = image.load_img(os.path.join(data_dir, image_path), target_size=image_shape)\n",
        "\n",
        "            # Convert PIL image to numpy ndarray\n",
        "            loaded_image = image.img_to_array(loaded_image)\n",
        "\n",
        "            # Add another dimension (Add batch dimension)\n",
        "            loaded_image = np.expand_dims(loaded_image, axis=0)\n",
        "\n",
        "            # Concatenate all images into one tensor\n",
        "            if images is None:\n",
        "                images = loaded_image\n",
        "            else:\n",
        "                images = np.concatenate([images, loaded_image], axis=0)\n",
        "        except Exception as e:\n",
        "            print(\"Error:\", i, e)\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXtKIcHx8pZ5"
      },
      "outputs": [],
      "source": [
        "def euclidean_distance_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Euclidean distance loss\n",
        "    https://en.wikipedia.org/wiki/Euclidean_distance\n",
        "    :param y_true: TensorFlow/Theano tensor\n",
        "    :param y_pred: TensorFlow/Theano tensor of the same shape as y_true\n",
        "    :return: float\n",
        "    \"\"\"\n",
        "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOOr-D9Z8rZb"
      },
      "outputs": [],
      "source": [
        "def write_log(callback, name, value, batch_no):\n",
        "    summary = tf.Summary()\n",
        "    summary_value = summary.value.add()\n",
        "    summary_value.simple_value = value\n",
        "    summary_value.tag = name\n",
        "    callback.writer.add_summary(summary, batch_no)\n",
        "    callback.writer.flush()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohaqzWtW8tMH"
      },
      "outputs": [],
      "source": [
        "def save_rgb_img(img, path):\n",
        "    \"\"\"\n",
        "    Save an rgb image\n",
        "    \"\"\"\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Image\")\n",
        "\n",
        "    plt.savefig(path)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7SX2htW-7mN"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "from scipy import io\n",
        "from scipy.io import loadmat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaTdEBmY8u3x",
        "outputId": "be73bf31-19f9-4d0f-8566-9e64248b5f78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:2.0379709601402283\n",
            "g_loss:0.6792522668838501\n",
            "Batch:2\n",
            "d_loss:0.4902947396039963\n",
            "g_loss:0.6795421838760376\n",
            "Batch:3\n",
            "d_loss:0.37825411185622215\n",
            "g_loss:0.6587579250335693\n",
            "Batch:4\n",
            "d_loss:0.2892937585711479\n",
            "g_loss:0.6368269324302673\n",
            "Batch:5\n",
            "d_loss:0.2297820895910263\n",
            "g_loss:0.6132293343544006\n",
            "Batch:6\n",
            "d_loss:0.1972133331000805\n",
            "g_loss:0.6037387847900391\n",
            "Batch:7\n",
            "d_loss:0.1892829374410212\n",
            "g_loss:0.5915494561195374\n",
            "Batch:8\n",
            "d_loss:0.18153416668064892\n",
            "g_loss:0.5857810378074646\n",
            "Batch:9\n",
            "d_loss:0.179028301499784\n",
            "g_loss:0.571650505065918\n",
            "Batch:10\n",
            "d_loss:0.17409439105540514\n",
            "g_loss:0.5645882487297058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.1736512102652341\n",
            "g_loss:0.547092080116272\n",
            "Batch:2\n",
            "d_loss:0.17352287261746824\n",
            "g_loss:0.5344910025596619\n",
            "Batch:3\n",
            "d_loss:0.17281660065054893\n",
            "g_loss:0.5222997069358826\n",
            "Batch:4\n",
            "d_loss:0.17162816389463842\n",
            "g_loss:0.5155307650566101\n",
            "Batch:5\n",
            "d_loss:0.174457976128906\n",
            "g_loss:0.4954818785190582\n",
            "Batch:6\n",
            "d_loss:0.17279178835451603\n",
            "g_loss:0.48427334427833557\n",
            "Batch:7\n",
            "d_loss:0.17268529697321355\n",
            "g_loss:0.4653475284576416\n",
            "Batch:8\n",
            "d_loss:0.17237607284914702\n",
            "g_loss:0.4627628028392792\n",
            "Batch:9\n",
            "d_loss:0.17204790527466685\n",
            "g_loss:0.4371303915977478\n",
            "Batch:10\n",
            "d_loss:0.17340996011625975\n",
            "g_loss:0.43817538022994995\n",
            "Epoch:2\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.17883199179777876\n",
            "g_loss:0.40770500898361206\n",
            "Batch:2\n",
            "d_loss:0.17580556904431432\n",
            "g_loss:0.4034728705883026\n",
            "Batch:3\n",
            "d_loss:0.1696104824077338\n",
            "g_loss:0.3902372717857361\n",
            "Batch:4\n",
            "d_loss:0.16823126649251208\n",
            "g_loss:0.38074126839637756\n",
            "Batch:5\n",
            "d_loss:0.17164562974357978\n",
            "g_loss:0.3595014810562134\n",
            "Batch:6\n",
            "d_loss:0.1734510895330459\n",
            "g_loss:0.33818578720092773\n",
            "Batch:7\n",
            "d_loss:0.16977443167706951\n",
            "g_loss:0.32763931155204773\n",
            "Batch:8\n",
            "d_loss:0.17080917744897306\n",
            "g_loss:0.3207070827484131\n",
            "Batch:9\n",
            "d_loss:0.17154215939808637\n",
            "g_loss:0.3035399913787842\n",
            "Batch:10\n",
            "d_loss:0.17738933581858873\n",
            "g_loss:0.2901570796966553\n",
            "Epoch:3\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.1737527719233185\n",
            "g_loss:0.2816566526889801\n",
            "Batch:2\n",
            "d_loss:0.17985343863256276\n",
            "g_loss:0.25948911905288696\n",
            "Batch:3\n",
            "d_loss:0.17500738595845178\n",
            "g_loss:0.25676947832107544\n",
            "Batch:4\n",
            "d_loss:0.17446154652861878\n",
            "g_loss:0.2543659210205078\n",
            "Batch:5\n",
            "d_loss:0.16993387939874083\n",
            "g_loss:0.23174622654914856\n",
            "Batch:6\n",
            "d_loss:0.17019421921577305\n",
            "g_loss:0.22713659703731537\n",
            "Batch:7\n",
            "d_loss:0.1712974199326709\n",
            "g_loss:0.21201267838478088\n",
            "Batch:8\n",
            "d_loss:0.17772439832333475\n",
            "g_loss:0.20677641034126282\n",
            "Batch:9\n",
            "d_loss:0.1744106879341416\n",
            "g_loss:0.18919016420841217\n",
            "Batch:10\n",
            "d_loss:0.1795391752384603\n",
            "g_loss:0.1841149479150772\n",
            "Epoch:4\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.17255740007385612\n",
            "g_loss:0.168665811419487\n",
            "Batch:2\n",
            "d_loss:0.17117052612593397\n",
            "g_loss:0.16671904921531677\n",
            "Batch:3\n",
            "d_loss:0.16958714509382844\n",
            "g_loss:0.15158134698867798\n",
            "Batch:4\n",
            "d_loss:0.17096219130326062\n",
            "g_loss:0.15315654873847961\n",
            "Batch:5\n",
            "d_loss:0.17142790590878576\n",
            "g_loss:0.13311339914798737\n",
            "Batch:6\n",
            "d_loss:0.1736006863648072\n",
            "g_loss:0.12973733246326447\n",
            "Batch:7\n",
            "d_loss:0.17423080408480018\n",
            "g_loss:0.11904266476631165\n",
            "Batch:8\n",
            "d_loss:0.16915103688370436\n",
            "g_loss:0.1202271580696106\n",
            "Batch:9\n",
            "d_loss:0.16864621976856142\n",
            "g_loss:0.10706378519535065\n",
            "Batch:10\n",
            "d_loss:0.1703467918559909\n",
            "g_loss:0.10610944032669067\n",
            "Epoch:5\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16896088002249599\n",
            "g_loss:0.09634888917207718\n",
            "Batch:2\n",
            "d_loss:0.17017630802001804\n",
            "g_loss:0.08937852829694748\n",
            "Batch:3\n",
            "d_loss:0.16924704954726622\n",
            "g_loss:0.08579693734645844\n",
            "Batch:4\n",
            "d_loss:0.1715284990496002\n",
            "g_loss:0.08182118833065033\n",
            "Batch:5\n",
            "d_loss:0.1726600385736674\n",
            "g_loss:0.0747215673327446\n",
            "Batch:6\n",
            "d_loss:0.182878089370206\n",
            "g_loss:0.06620877981185913\n",
            "Batch:7\n",
            "d_loss:0.1696431590244174\n",
            "g_loss:0.06583928316831589\n",
            "Batch:8\n",
            "d_loss:0.16651733528124169\n",
            "g_loss:0.06573830544948578\n",
            "Batch:9\n",
            "d_loss:0.16832373570650816\n",
            "g_loss:0.05626244843006134\n",
            "Batch:10\n",
            "d_loss:0.1697529595112428\n",
            "g_loss:0.059109773486852646\n",
            "Epoch:6\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16911401401739568\n",
            "g_loss:0.048612430691719055\n",
            "Batch:2\n",
            "d_loss:0.1707636540522799\n",
            "g_loss:0.050621405243873596\n",
            "Batch:3\n",
            "d_loss:0.1675605842610821\n",
            "g_loss:0.04309992864727974\n",
            "Batch:4\n",
            "d_loss:0.17147763338289224\n",
            "g_loss:0.045762572437524796\n",
            "Batch:5\n",
            "d_loss:0.1714350939146243\n",
            "g_loss:0.03587278351187706\n",
            "Batch:6\n",
            "d_loss:0.1798654820304364\n",
            "g_loss:0.037458792328834534\n",
            "Batch:7\n",
            "d_loss:0.1727955003734678\n",
            "g_loss:0.03144227713346481\n",
            "Batch:8\n",
            "d_loss:0.17605202551931143\n",
            "g_loss:0.03420291841030121\n",
            "Batch:9\n",
            "d_loss:0.17066473711747676\n",
            "g_loss:0.029195087030529976\n",
            "Batch:10\n",
            "d_loss:0.17593953874893486\n",
            "g_loss:0.02923578955233097\n",
            "Epoch:7\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.1701167670544237\n",
            "g_loss:0.025993965566158295\n",
            "Batch:2\n",
            "d_loss:0.1757425972027704\n",
            "g_loss:0.0235256627202034\n",
            "Batch:3\n",
            "d_loss:0.17319742869585752\n",
            "g_loss:0.02343733422458172\n",
            "Batch:4\n",
            "d_loss:0.17156612646067515\n",
            "g_loss:0.023846935480833054\n",
            "Batch:5\n",
            "d_loss:0.16878422477748245\n",
            "g_loss:0.020404152572155\n",
            "Batch:6\n",
            "d_loss:0.1695945046376437\n",
            "g_loss:0.019671572372317314\n",
            "Batch:7\n",
            "d_loss:0.16630244016414508\n",
            "g_loss:0.017790624871850014\n",
            "Batch:8\n",
            "d_loss:0.1667871723184362\n",
            "g_loss:0.017946451902389526\n",
            "Batch:9\n",
            "d_loss:0.16674161842092872\n",
            "g_loss:0.015454782173037529\n",
            "Batch:10\n",
            "d_loss:0.16809794295113534\n",
            "g_loss:0.01631254330277443\n",
            "Epoch:8\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.1682093717972748\n",
            "g_loss:0.013313613831996918\n",
            "Batch:2\n",
            "d_loss:0.173672420962248\n",
            "g_loss:0.013030177913606167\n",
            "Batch:3\n",
            "d_loss:0.17824157368158922\n",
            "g_loss:0.01191779226064682\n",
            "Batch:4\n",
            "d_loss:0.17272008262807503\n",
            "g_loss:0.012558311223983765\n",
            "Batch:5\n",
            "d_loss:0.16886247109505348\n",
            "g_loss:0.010992234572768211\n",
            "Batch:6\n",
            "d_loss:0.1697384690050967\n",
            "g_loss:0.01025540940463543\n",
            "Batch:7\n",
            "d_loss:0.16779248276725411\n",
            "g_loss:0.009853772819042206\n",
            "Batch:8\n",
            "d_loss:0.16759448446100578\n",
            "g_loss:0.00928874034434557\n",
            "Batch:9\n",
            "d_loss:0.16696091048652306\n",
            "g_loss:0.008719886653125286\n",
            "Batch:10\n",
            "d_loss:0.16718406282598153\n",
            "g_loss:0.008744795806705952\n",
            "Epoch:9\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16641978459665552\n",
            "g_loss:0.007842307910323143\n",
            "Batch:2\n",
            "d_loss:0.1665688635839615\n",
            "g_loss:0.00739986402913928\n",
            "Batch:3\n",
            "d_loss:0.16577539005083963\n",
            "g_loss:0.00711491284891963\n",
            "Batch:4\n",
            "d_loss:0.16650181863224134\n",
            "g_loss:0.0072621447034180164\n",
            "Batch:5\n",
            "d_loss:0.1681798439240083\n",
            "g_loss:0.005915866699069738\n",
            "Batch:6\n",
            "d_loss:0.17056870786473155\n",
            "g_loss:0.005943119525909424\n",
            "Batch:7\n",
            "d_loss:0.17170478717889637\n",
            "g_loss:0.005522798281162977\n",
            "Batch:8\n",
            "d_loss:0.16689998959191144\n",
            "g_loss:0.006045414134860039\n",
            "Batch:9\n",
            "d_loss:0.16639339082757942\n",
            "g_loss:0.00506547698751092\n",
            "Batch:10\n",
            "d_loss:0.16753638500813395\n",
            "g_loss:0.005856521427631378\n",
            "Epoch:10\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.1678952425136231\n",
            "g_loss:0.004228461068123579\n",
            "Batch:2\n",
            "d_loss:0.17125594784738496\n",
            "g_loss:0.005106272175908089\n",
            "Batch:3\n",
            "d_loss:0.16999768995447084\n",
            "g_loss:0.003691293066367507\n",
            "Batch:4\n",
            "d_loss:0.1858612872310914\n",
            "g_loss:0.004975015763193369\n",
            "Batch:5\n",
            "d_loss:0.16879359347512946\n",
            "g_loss:0.004018855281174183\n",
            "Batch:6\n",
            "d_loss:0.16948598466115072\n",
            "g_loss:0.004251962527632713\n",
            "Batch:7\n",
            "d_loss:0.1672683983342722\n",
            "g_loss:0.003796536708250642\n",
            "Batch:8\n",
            "d_loss:0.1697438961127773\n",
            "g_loss:0.004497641231864691\n",
            "Batch:9\n",
            "d_loss:0.16966311924625188\n",
            "g_loss:0.0034963747020810843\n",
            "Batch:10\n",
            "d_loss:0.17757203720975667\n",
            "g_loss:0.0043259793892502785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:11\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16716831433586776\n",
            "g_loss:0.0036702014040201902\n",
            "Batch:2\n",
            "d_loss:0.166519331978634\n",
            "g_loss:0.003937118221074343\n",
            "Batch:3\n",
            "d_loss:0.1655619193916209\n",
            "g_loss:0.003537834156304598\n",
            "Batch:4\n",
            "d_loss:0.16596013074740767\n",
            "g_loss:0.004226128105074167\n",
            "Batch:5\n",
            "d_loss:0.16693975479574874\n",
            "g_loss:0.0031853271648287773\n",
            "Batch:6\n",
            "d_loss:0.1672261749044992\n",
            "g_loss:0.0040627592243254185\n",
            "Batch:7\n",
            "d_loss:0.16753678023815155\n",
            "g_loss:0.00298757990822196\n",
            "Batch:8\n",
            "d_loss:0.17070589534705505\n",
            "g_loss:0.0045927162282168865\n",
            "Batch:9\n",
            "d_loss:0.17006630287505686\n",
            "g_loss:0.002959236968308687\n",
            "Batch:10\n",
            "d_loss:0.17426366719882935\n",
            "g_loss:0.004840559791773558\n",
            "Epoch:12\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.1686262974399142\n",
            "g_loss:0.003328832797706127\n",
            "Batch:2\n",
            "d_loss:0.16903139249188825\n",
            "g_loss:0.004404143895953894\n",
            "Batch:3\n",
            "d_loss:0.16686281556030735\n",
            "g_loss:0.0032732936087995768\n",
            "Batch:4\n",
            "d_loss:0.17068897507851943\n",
            "g_loss:0.004595199599862099\n",
            "Batch:5\n",
            "d_loss:0.17286959144985303\n",
            "g_loss:0.0031241450924426317\n",
            "Batch:6\n",
            "d_loss:0.1760359613399487\n",
            "g_loss:0.003738034749403596\n",
            "Batch:7\n",
            "d_loss:0.17810497648315504\n",
            "g_loss:0.003619360737502575\n",
            "Batch:8\n",
            "d_loss:0.16818670672364533\n",
            "g_loss:0.0036256012972444296\n",
            "Batch:9\n",
            "d_loss:0.17017575175850652\n",
            "g_loss:0.004300362430512905\n",
            "Batch:10\n",
            "d_loss:0.17532756482250988\n",
            "g_loss:0.0031514493748545647\n",
            "Epoch:13\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.17177314119180664\n",
            "g_loss:0.004288313444703817\n",
            "Batch:2\n",
            "d_loss:0.1687495739897713\n",
            "g_loss:0.0028117059264332056\n",
            "Batch:3\n",
            "d_loss:0.1717780198669061\n",
            "g_loss:0.004462545271962881\n",
            "Batch:4\n",
            "d_loss:0.16694378334796056\n",
            "g_loss:0.004235375206917524\n",
            "Batch:5\n",
            "d_loss:0.17290098022203892\n",
            "g_loss:0.004477427341043949\n",
            "Batch:6\n",
            "d_loss:0.1711269072839059\n",
            "g_loss:0.003910397179424763\n",
            "Batch:7\n",
            "d_loss:0.18001567642204463\n",
            "g_loss:0.005784105975180864\n",
            "Batch:8\n",
            "d_loss:0.16761731531005353\n",
            "g_loss:0.005640207789838314\n",
            "Batch:9\n",
            "d_loss:0.16588650038465858\n",
            "g_loss:0.0063673462718725204\n",
            "Batch:10\n",
            "d_loss:0.1645515444688499\n",
            "g_loss:0.007366554345935583\n",
            "Epoch:14\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16649181977845728\n",
            "g_loss:0.005368215497583151\n",
            "Batch:2\n",
            "d_loss:0.16638474690262228\n",
            "g_loss:0.007586407940834761\n",
            "Batch:3\n",
            "d_loss:0.16793889575637877\n",
            "g_loss:0.004416261333972216\n",
            "Batch:4\n",
            "d_loss:0.17402038571890444\n",
            "g_loss:0.008106485940515995\n",
            "Batch:5\n",
            "d_loss:0.17247074155602604\n",
            "g_loss:0.004487212281674147\n",
            "Batch:6\n",
            "d_loss:0.1759812207892537\n",
            "g_loss:0.009977288544178009\n",
            "Batch:7\n",
            "d_loss:0.23951055109500885\n",
            "g_loss:0.7049868702888489\n",
            "Batch:8\n",
            "d_loss:3.382229834794998\n",
            "g_loss:4.915331840515137\n",
            "Batch:9\n",
            "d_loss:1.912785455584526\n",
            "g_loss:0.12530115246772766\n",
            "Batch:10\n",
            "d_loss:0.7269845828413963\n",
            "g_loss:0.20043522119522095\n",
            "Epoch:15\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.3630867376923561\n",
            "g_loss:0.2801385521888733\n",
            "Batch:2\n",
            "d_loss:0.2298793497029692\n",
            "g_loss:0.1178724393248558\n",
            "Batch:3\n",
            "d_loss:0.44986841082572937\n",
            "g_loss:4.636027812957764\n",
            "Batch:4\n",
            "d_loss:0.6879058256745338\n",
            "g_loss:0.1397884488105774\n",
            "Batch:5\n",
            "d_loss:0.23340930603444576\n",
            "g_loss:0.012956606224179268\n",
            "Batch:6\n",
            "d_loss:0.2291098264977336\n",
            "g_loss:0.012961205095052719\n",
            "Batch:7\n",
            "d_loss:0.22123019327409565\n",
            "g_loss:0.014936551451683044\n",
            "Batch:8\n",
            "d_loss:0.20915878610685468\n",
            "g_loss:0.012907600030303001\n",
            "Batch:9\n",
            "d_loss:0.19890005979686975\n",
            "g_loss:0.010978196747601032\n",
            "Batch:10\n",
            "d_loss:0.1911773340543732\n",
            "g_loss:0.013338603079319\n",
            "Epoch:16\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.1900269853649661\n",
            "g_loss:0.012517641298472881\n",
            "Batch:2\n",
            "d_loss:0.18573707330506295\n",
            "g_loss:0.014552123844623566\n",
            "Batch:3\n",
            "d_loss:0.18672869267174974\n",
            "g_loss:0.01426314003765583\n",
            "Batch:4\n",
            "d_loss:0.17966073099523783\n",
            "g_loss:0.0167547594755888\n",
            "Batch:5\n",
            "d_loss:0.17813125951215625\n",
            "g_loss:0.015895603224635124\n",
            "Batch:6\n",
            "d_loss:0.17968909279443324\n",
            "g_loss:0.01513893436640501\n",
            "Batch:7\n",
            "d_loss:0.17920320405391976\n",
            "g_loss:0.015512990765273571\n",
            "Batch:8\n",
            "d_loss:0.17545201355824247\n",
            "g_loss:0.014978630468249321\n",
            "Batch:9\n",
            "d_loss:0.17491598398191854\n",
            "g_loss:0.015929970890283585\n",
            "Batch:10\n",
            "d_loss:0.17209777497919276\n",
            "g_loss:0.015627505257725716\n",
            "Epoch:17\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.17249159939819947\n",
            "g_loss:0.01632780022919178\n",
            "Batch:2\n",
            "d_loss:0.1710471980040893\n",
            "g_loss:0.014922801405191422\n",
            "Batch:3\n",
            "d_loss:0.17269859759835526\n",
            "g_loss:0.013857332989573479\n",
            "Batch:4\n",
            "d_loss:0.1698674334329553\n",
            "g_loss:0.01618935726583004\n",
            "Batch:5\n",
            "d_loss:0.16990130592603236\n",
            "g_loss:0.016486644744873047\n",
            "Batch:6\n",
            "d_loss:0.1706203460053075\n",
            "g_loss:0.015036921948194504\n",
            "Batch:7\n",
            "d_loss:0.17062393366359174\n",
            "g_loss:0.014043052680790424\n",
            "Batch:8\n",
            "d_loss:0.1687068262253888\n",
            "g_loss:0.015362030826508999\n",
            "Batch:9\n",
            "d_loss:0.16911523710587062\n",
            "g_loss:0.015501189976930618\n",
            "Batch:10\n",
            "d_loss:0.16760772638372146\n",
            "g_loss:0.015743758529424667\n",
            "Epoch:18\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16796088355476968\n",
            "g_loss:0.014814822003245354\n",
            "Batch:2\n",
            "d_loss:0.1672283095831517\n",
            "g_loss:0.013898513279855251\n",
            "Batch:3\n",
            "d_loss:0.1685081359173637\n",
            "g_loss:0.01280672661960125\n",
            "Batch:4\n",
            "d_loss:0.16711427801055834\n",
            "g_loss:0.015128115192055702\n",
            "Batch:5\n",
            "d_loss:0.16721246016095392\n",
            "g_loss:0.015076116658747196\n",
            "Batch:6\n",
            "d_loss:0.16758830033359118\n",
            "g_loss:0.013756777159869671\n",
            "Batch:7\n",
            "d_loss:0.16762918449239805\n",
            "g_loss:0.01311773993074894\n",
            "Batch:8\n",
            "d_loss:0.16652492884895764\n",
            "g_loss:0.01449036318808794\n",
            "Batch:9\n",
            "d_loss:0.16687657788861543\n",
            "g_loss:0.013386611826717854\n",
            "Batch:10\n",
            "d_loss:0.16595022525871173\n",
            "g_loss:0.01415828987956047\n",
            "Epoch:19\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16623965263715945\n",
            "g_loss:0.01332681905478239\n",
            "Batch:2\n",
            "d_loss:0.16573286039056256\n",
            "g_loss:0.012595894746482372\n",
            "Batch:3\n",
            "d_loss:0.16670266003347933\n",
            "g_loss:0.011381486430764198\n",
            "Batch:4\n",
            "d_loss:0.16594606771832332\n",
            "g_loss:0.0132491085678339\n",
            "Batch:5\n",
            "d_loss:0.166020759701496\n",
            "g_loss:0.01260905247181654\n",
            "Batch:6\n",
            "d_loss:0.1661990052089095\n",
            "g_loss:0.012019649147987366\n",
            "Batch:7\n",
            "d_loss:0.16621759108966216\n",
            "g_loss:0.011239903047680855\n",
            "Batch:8\n",
            "d_loss:0.16552276839502156\n",
            "g_loss:0.012040629982948303\n",
            "Batch:9\n",
            "d_loss:0.16576215019449592\n",
            "g_loss:0.011334973387420177\n",
            "Batch:10\n",
            "d_loss:0.16514716934761964\n",
            "g_loss:0.011865255422890186\n",
            "Epoch:20\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16538501071045175\n",
            "g_loss:0.011117820627987385\n",
            "Batch:2\n",
            "d_loss:0.16499826338258572\n",
            "g_loss:0.010639043524861336\n",
            "Batch:3\n",
            "d_loss:0.16572173466556706\n",
            "g_loss:0.009691859595477581\n",
            "Batch:4\n",
            "d_loss:0.16531828670122195\n",
            "g_loss:0.011938679032027721\n",
            "Batch:5\n",
            "d_loss:0.1653214579273481\n",
            "g_loss:0.010549887083470821\n",
            "Batch:6\n",
            "d_loss:0.1654238854389405\n",
            "g_loss:0.009560184553265572\n",
            "Batch:7\n",
            "d_loss:0.16542530589504167\n",
            "g_loss:0.009753378108143806\n",
            "Batch:8\n",
            "d_loss:0.16497002355754375\n",
            "g_loss:0.009751362726092339\n",
            "Batch:9\n",
            "d_loss:0.16511943817022257\n",
            "g_loss:0.009735191240906715\n",
            "Batch:10\n",
            "d_loss:0.16466915640921798\n",
            "g_loss:0.009956305846571922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:21\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16489052088581957\n",
            "g_loss:0.009192142635583878\n",
            "Batch:2\n",
            "d_loss:0.16454706779040862\n",
            "g_loss:0.008667385205626488\n",
            "Batch:3\n",
            "d_loss:0.16513054618553724\n",
            "g_loss:0.00827927328646183\n",
            "Batch:4\n",
            "d_loss:0.16493771108798683\n",
            "g_loss:0.009577689692378044\n",
            "Batch:5\n",
            "d_loss:0.1648898528655991\n",
            "g_loss:0.009102198295295238\n",
            "Batch:6\n",
            "d_loss:0.1649479036568664\n",
            "g_loss:0.008259241469204426\n",
            "Batch:7\n",
            "d_loss:0.1649364432087168\n",
            "g_loss:0.008038724772632122\n",
            "Batch:8\n",
            "d_loss:0.1646300945430994\n",
            "g_loss:0.008418199606239796\n",
            "Batch:9\n",
            "d_loss:0.1646959764912026\n",
            "g_loss:0.00816929992288351\n",
            "Batch:10\n",
            "d_loss:0.16436130191141274\n",
            "g_loss:0.008718360215425491\n",
            "Epoch:22\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16455758638039697\n",
            "g_loss:0.008032817393541336\n",
            "Batch:2\n",
            "d_loss:0.16427944441966247\n",
            "g_loss:0.007647255435585976\n",
            "Batch:3\n",
            "d_loss:0.16473028356267605\n",
            "g_loss:0.0072901020757853985\n",
            "Batch:4\n",
            "d_loss:0.1646782335883472\n",
            "g_loss:0.008469273336231709\n",
            "Batch:5\n",
            "d_loss:0.1646068039990496\n",
            "g_loss:0.007840895093977451\n",
            "Batch:6\n",
            "d_loss:0.1646432045235997\n",
            "g_loss:0.007376405876129866\n",
            "Batch:7\n",
            "d_loss:0.1646238041575998\n",
            "g_loss:0.0069078681990504265\n",
            "Batch:8\n",
            "d_loss:0.16439696718589403\n",
            "g_loss:0.007512668613344431\n",
            "Batch:9\n",
            "d_loss:0.16441965497506317\n",
            "g_loss:0.007171301171183586\n",
            "Batch:10\n",
            "d_loss:0.16416690887126606\n",
            "g_loss:0.007694887928664684\n",
            "Epoch:23\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16434485891659278\n",
            "g_loss:0.006930055562406778\n",
            "Batch:2\n",
            "d_loss:0.16408004179538693\n",
            "g_loss:0.00676738191395998\n",
            "Batch:3\n",
            "d_loss:0.1644604660978075\n",
            "g_loss:0.006463038269430399\n",
            "Batch:4\n",
            "d_loss:0.16452521353494376\n",
            "g_loss:0.007673072628676891\n",
            "Batch:5\n",
            "d_loss:0.16439263192296494\n",
            "g_loss:0.007103445939719677\n",
            "Batch:6\n",
            "d_loss:0.16441271679650526\n",
            "g_loss:0.006503976881504059\n",
            "Batch:7\n",
            "d_loss:0.16441643540747464\n",
            "g_loss:0.0063406252302229404\n",
            "Batch:8\n",
            "d_loss:0.16425545427773613\n",
            "g_loss:0.00685041444376111\n",
            "Batch:9\n",
            "d_loss:0.16422844014596194\n",
            "g_loss:0.006662553176283836\n",
            "Batch:10\n",
            "d_loss:0.16401440018671565\n",
            "g_loss:0.007066349033266306\n",
            "Epoch:24\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.1641975719394395\n",
            "g_loss:0.0067853122018277645\n",
            "Batch:2\n",
            "d_loss:0.16395796976576094\n",
            "g_loss:0.0063471803441643715\n",
            "Batch:3\n",
            "d_loss:0.16426881348888855\n",
            "g_loss:0.005974383093416691\n",
            "Batch:4\n",
            "d_loss:0.16436821794195566\n",
            "g_loss:0.007363647688180208\n",
            "Batch:5\n",
            "d_loss:0.16425398898718413\n",
            "g_loss:0.0066665480844676495\n",
            "Batch:6\n",
            "d_loss:0.16425890634127427\n",
            "g_loss:0.0061178067699074745\n",
            "Batch:7\n",
            "d_loss:0.16424283175729215\n",
            "g_loss:0.006166350096464157\n",
            "Batch:8\n",
            "d_loss:0.1641222518956056\n",
            "g_loss:0.006514802109450102\n",
            "Batch:9\n",
            "d_loss:0.16412291122833267\n",
            "g_loss:0.006465141661465168\n",
            "Batch:10\n",
            "d_loss:0.1639118202001555\n",
            "g_loss:0.006860591471195221\n",
            "Epoch:25\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16408734626020305\n",
            "g_loss:0.006296617444604635\n",
            "Batch:2\n",
            "d_loss:0.16388038563309237\n",
            "g_loss:0.006158692762255669\n",
            "Batch:3\n",
            "d_loss:0.16416367591591552\n",
            "g_loss:0.0057603768073022366\n",
            "Batch:4\n",
            "d_loss:0.16432168168830685\n",
            "g_loss:0.0070135039277374744\n",
            "Batch:5\n",
            "d_loss:0.16417352369171567\n",
            "g_loss:0.006501223426312208\n",
            "Batch:6\n",
            "d_loss:0.16417745666694827\n",
            "g_loss:0.006177258677780628\n",
            "Batch:7\n",
            "d_loss:0.16411230200901628\n",
            "g_loss:0.005983650218695402\n",
            "Batch:8\n",
            "d_loss:0.16405410107108764\n",
            "g_loss:0.0065733338706195354\n",
            "Batch:9\n",
            "d_loss:0.16402909034513868\n",
            "g_loss:0.006563746370375156\n",
            "Batch:10\n",
            "d_loss:0.1638386604608968\n",
            "g_loss:0.007022783160209656\n",
            "Epoch:26\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16403112447005697\n",
            "g_loss:0.006473100744187832\n",
            "Batch:2\n",
            "d_loss:0.16382080907351337\n",
            "g_loss:0.00618181424215436\n",
            "Batch:3\n",
            "d_loss:0.16404528406565078\n",
            "g_loss:0.005726361181586981\n",
            "Batch:4\n",
            "d_loss:0.16421914784586988\n",
            "g_loss:0.007075130939483643\n",
            "Batch:5\n",
            "d_loss:0.16407593848998658\n",
            "g_loss:0.006539326161146164\n",
            "Batch:6\n",
            "d_loss:0.16408300018520094\n",
            "g_loss:0.006098640151321888\n",
            "Batch:7\n",
            "d_loss:0.16405855800257996\n",
            "g_loss:0.006134568247944117\n",
            "Batch:8\n",
            "d_loss:0.16397309250896797\n",
            "g_loss:0.00657568359747529\n",
            "Batch:9\n",
            "d_loss:0.16390810545999557\n",
            "g_loss:0.006660293322056532\n",
            "Batch:10\n",
            "d_loss:0.16377736697904766\n",
            "g_loss:0.006968675646930933\n",
            "Epoch:27\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16392303130123764\n",
            "g_loss:0.006490679923444986\n",
            "Batch:2\n",
            "d_loss:0.1637294248212129\n",
            "g_loss:0.006424865685403347\n",
            "Batch:3\n",
            "d_loss:0.1639433963864576\n",
            "g_loss:0.006179994437843561\n",
            "Batch:4\n",
            "d_loss:0.16416024981299415\n",
            "g_loss:0.007536905352026224\n",
            "Batch:5\n",
            "d_loss:0.16400941740721464\n",
            "g_loss:0.006884571630507708\n",
            "Batch:6\n",
            "d_loss:0.16399812625604682\n",
            "g_loss:0.006322527304291725\n",
            "Batch:7\n",
            "d_loss:0.16396542749134824\n",
            "g_loss:0.006301590241491795\n",
            "Batch:8\n",
            "d_loss:0.1639177400211338\n",
            "g_loss:0.007214672863483429\n",
            "Batch:9\n",
            "d_loss:0.1638034759380389\n",
            "g_loss:0.006867886520922184\n",
            "Batch:10\n",
            "d_loss:0.16370866197394207\n",
            "g_loss:0.0073540667071938515\n",
            "Epoch:28\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16388666021521203\n",
            "g_loss:0.006826800759881735\n",
            "Batch:2\n",
            "d_loss:0.16367463130154647\n",
            "g_loss:0.006696140393614769\n",
            "Batch:3\n",
            "d_loss:0.16383468700223602\n",
            "g_loss:0.006411189679056406\n",
            "Batch:4\n",
            "d_loss:0.16412635083543137\n",
            "g_loss:0.007945341989398003\n",
            "Batch:5\n",
            "d_loss:0.16398820126778446\n",
            "g_loss:0.007340406533330679\n",
            "Batch:6\n",
            "d_loss:0.16388551535783336\n",
            "g_loss:0.006663598585873842\n",
            "Batch:7\n",
            "d_loss:0.16387410563766025\n",
            "g_loss:0.006895285099744797\n",
            "Batch:8\n",
            "d_loss:0.163850945973536\n",
            "g_loss:0.007608763873577118\n",
            "Batch:9\n",
            "d_loss:0.16375961442827247\n",
            "g_loss:0.007446927018463612\n",
            "Batch:10\n",
            "d_loss:0.16362563996517565\n",
            "g_loss:0.008307982236146927\n",
            "Epoch:29\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16382522622006945\n",
            "g_loss:0.007535608485341072\n",
            "Batch:2\n",
            "d_loss:0.16359260526951402\n",
            "g_loss:0.007256295066326857\n",
            "Batch:3\n",
            "d_loss:0.1638069979089778\n",
            "g_loss:0.007058566901832819\n",
            "Batch:4\n",
            "d_loss:0.16404926229733974\n",
            "g_loss:0.008565502241253853\n",
            "Batch:5\n",
            "d_loss:0.1638626202766318\n",
            "g_loss:0.00778413750231266\n",
            "Batch:6\n",
            "d_loss:0.16388024296611547\n",
            "g_loss:0.007478139363229275\n",
            "Batch:7\n",
            "d_loss:0.16377613277290948\n",
            "g_loss:0.0077368831261992455\n",
            "Batch:8\n",
            "d_loss:0.16381570446537808\n",
            "g_loss:0.008260749280452728\n",
            "Batch:9\n",
            "d_loss:0.16374377385363914\n",
            "g_loss:0.008137388154864311\n",
            "Batch:10\n",
            "d_loss:0.16356493956118356\n",
            "g_loss:0.008806520141661167\n",
            "Epoch:30\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16375278317718767\n",
            "g_loss:0.008120765909552574\n",
            "Batch:2\n",
            "d_loss:0.16358169814338908\n",
            "g_loss:0.008074628189206123\n",
            "Batch:3\n",
            "d_loss:0.16370550080318935\n",
            "g_loss:0.007766750641167164\n",
            "Batch:4\n",
            "d_loss:0.16402397607453167\n",
            "g_loss:0.009359869174659252\n",
            "Batch:5\n",
            "d_loss:0.16393196041462943\n",
            "g_loss:0.008866493590176105\n",
            "Batch:6\n",
            "d_loss:0.16379487034282647\n",
            "g_loss:0.008122771978378296\n",
            "Batch:7\n",
            "d_loss:0.16378858927055262\n",
            "g_loss:0.008621850050985813\n",
            "Batch:8\n",
            "d_loss:0.1638408874568995\n",
            "g_loss:0.009731793776154518\n",
            "Batch:9\n",
            "d_loss:0.16370646911673248\n",
            "g_loss:0.009208542294800282\n",
            "Batch:10\n",
            "d_loss:0.1635938009712845\n",
            "g_loss:0.01029533427208662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:31\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16375264353700913\n",
            "g_loss:0.009743466973304749\n",
            "Batch:2\n",
            "d_loss:0.16354392748326063\n",
            "g_loss:0.009420209564268589\n",
            "Batch:3\n",
            "d_loss:0.16371451469603926\n",
            "g_loss:0.009319063276052475\n",
            "Batch:4\n",
            "d_loss:0.16400850127683952\n",
            "g_loss:0.011818055994808674\n",
            "Batch:5\n",
            "d_loss:0.1638421209063381\n",
            "g_loss:0.010359421372413635\n",
            "Batch:6\n",
            "d_loss:0.1637833055574447\n",
            "g_loss:0.009890557266771793\n",
            "Batch:7\n",
            "d_loss:0.16375003728899173\n",
            "g_loss:0.009979570284485817\n",
            "Batch:8\n",
            "d_loss:0.16381001245463267\n",
            "g_loss:0.011935155838727951\n",
            "Batch:9\n",
            "d_loss:0.163731389970053\n",
            "g_loss:0.011275017634034157\n",
            "Batch:10\n",
            "d_loss:0.1636538100137841\n",
            "g_loss:0.013374184258282185\n",
            "Epoch:32\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16379019094165415\n",
            "g_loss:0.011906265281140804\n",
            "Batch:2\n",
            "d_loss:0.16360050957882777\n",
            "g_loss:0.011920083314180374\n",
            "Batch:3\n",
            "d_loss:0.16364761083968915\n",
            "g_loss:0.011503573507070541\n",
            "Batch:4\n",
            "d_loss:0.16398365516215563\n",
            "g_loss:0.01477325800806284\n",
            "Batch:5\n",
            "d_loss:0.16387585032498464\n",
            "g_loss:0.013171468861401081\n",
            "Batch:6\n",
            "d_loss:0.16387015889631584\n",
            "g_loss:0.012789389118552208\n",
            "Batch:7\n",
            "d_loss:0.16377254779217765\n",
            "g_loss:0.013217221945524216\n",
            "Batch:8\n",
            "d_loss:0.16382596039329655\n",
            "g_loss:0.015503429807722569\n",
            "Batch:9\n",
            "d_loss:0.16368711131508462\n",
            "g_loss:0.01479422952979803\n",
            "Batch:10\n",
            "d_loss:0.16360739755327813\n",
            "g_loss:0.01657702960073948\n",
            "Epoch:33\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16371256089769304\n",
            "g_loss:0.015332374721765518\n",
            "Batch:2\n",
            "d_loss:0.16359859117073938\n",
            "g_loss:0.015071707777678967\n",
            "Batch:3\n",
            "d_loss:0.16372696094913408\n",
            "g_loss:0.015117043629288673\n",
            "Batch:4\n",
            "d_loss:0.16402996913529932\n",
            "g_loss:0.01850970648229122\n",
            "Batch:5\n",
            "d_loss:0.16399961759452708\n",
            "g_loss:0.016719162464141846\n",
            "Batch:6\n",
            "d_loss:0.16391344636213034\n",
            "g_loss:0.016137726604938507\n",
            "Batch:7\n",
            "d_loss:0.16374917567009106\n",
            "g_loss:0.01711619459092617\n",
            "Batch:8\n",
            "d_loss:0.16384477194515057\n",
            "g_loss:0.020251167938113213\n",
            "Batch:9\n",
            "d_loss:0.1638038479431998\n",
            "g_loss:0.019585756585001945\n",
            "Batch:10\n",
            "d_loss:0.16356405630358495\n",
            "g_loss:0.0221624244004488\n",
            "Epoch:34\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.1639159646583721\n",
            "g_loss:0.020285192877054214\n",
            "Batch:2\n",
            "d_loss:0.1636203353118617\n",
            "g_loss:0.02057551220059395\n",
            "Batch:3\n",
            "d_loss:0.1638393034809269\n",
            "g_loss:0.02013116143643856\n",
            "Batch:4\n",
            "d_loss:0.164105514268158\n",
            "g_loss:0.025772850960493088\n",
            "Batch:5\n",
            "d_loss:0.16407501912908629\n",
            "g_loss:0.022956684231758118\n",
            "Batch:6\n",
            "d_loss:0.16384048337931745\n",
            "g_loss:0.022356942296028137\n",
            "Batch:7\n",
            "d_loss:0.16383264440810308\n",
            "g_loss:0.022335371002554893\n",
            "Batch:8\n",
            "d_loss:0.16385350318159908\n",
            "g_loss:0.026300353929400444\n",
            "Batch:9\n",
            "d_loss:0.16382094117579982\n",
            "g_loss:0.024057814851403236\n",
            "Batch:10\n",
            "d_loss:0.16364953617448919\n",
            "g_loss:0.026206133887171745\n",
            "Epoch:35\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16397748357849196\n",
            "g_loss:0.023111896589398384\n",
            "Batch:2\n",
            "d_loss:0.16360030727810226\n",
            "g_loss:0.022565100342035294\n",
            "Batch:3\n",
            "d_loss:0.16376704891445115\n",
            "g_loss:0.020688608288764954\n",
            "Batch:4\n",
            "d_loss:0.1642990083200857\n",
            "g_loss:0.02621343918144703\n",
            "Batch:5\n",
            "d_loss:0.16428561200154945\n",
            "g_loss:0.02288273721933365\n",
            "Batch:6\n",
            "d_loss:0.1639557679882273\n",
            "g_loss:0.022123001515865326\n",
            "Batch:7\n",
            "d_loss:0.16396003059344366\n",
            "g_loss:0.02263357862830162\n",
            "Batch:8\n",
            "d_loss:0.16408928472083062\n",
            "g_loss:0.027043849229812622\n",
            "Batch:9\n",
            "d_loss:0.16399628639919683\n",
            "g_loss:0.024739470332860947\n",
            "Batch:10\n",
            "d_loss:0.16386682289885357\n",
            "g_loss:0.029840640723705292\n",
            "Epoch:36\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.1641130949719809\n",
            "g_loss:0.026720236986875534\n",
            "Batch:2\n",
            "d_loss:0.16387523390585557\n",
            "g_loss:0.02783866412937641\n",
            "Batch:3\n",
            "d_loss:0.16393186285858974\n",
            "g_loss:0.02743620052933693\n",
            "Batch:4\n",
            "d_loss:0.16448721231427044\n",
            "g_loss:0.03690310940146446\n",
            "Batch:5\n",
            "d_loss:0.1644430952728726\n",
            "g_loss:0.033229727298021317\n",
            "Batch:6\n",
            "d_loss:0.16405750927515328\n",
            "g_loss:0.031743746250867844\n",
            "Batch:7\n",
            "d_loss:0.16395486175315455\n",
            "g_loss:0.03369636833667755\n",
            "Batch:8\n",
            "d_loss:0.16406135784927756\n",
            "g_loss:0.04095727205276489\n",
            "Batch:9\n",
            "d_loss:0.16401838784804568\n",
            "g_loss:0.035851288586854935\n",
            "Batch:10\n",
            "d_loss:0.16403970128158107\n",
            "g_loss:0.04448128864169121\n",
            "Epoch:37\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16424787556752563\n",
            "g_loss:0.03776329383254051\n",
            "Batch:2\n",
            "d_loss:0.16383438906632364\n",
            "g_loss:0.04135041683912277\n",
            "Batch:3\n",
            "d_loss:0.16390362905804068\n",
            "g_loss:0.0375354066491127\n",
            "Batch:4\n",
            "d_loss:0.16468049719696864\n",
            "g_loss:0.052030108869075775\n",
            "Batch:5\n",
            "d_loss:0.1645116891595535\n",
            "g_loss:0.04441118240356445\n",
            "Batch:6\n",
            "d_loss:0.1642099741147831\n",
            "g_loss:0.04199425131082535\n",
            "Batch:7\n",
            "d_loss:0.16427178762387484\n",
            "g_loss:0.04416903108358383\n",
            "Batch:8\n",
            "d_loss:0.16436762368539348\n",
            "g_loss:0.05756010487675667\n",
            "Batch:9\n",
            "d_loss:0.16428472235566005\n",
            "g_loss:0.050346001982688904\n",
            "Batch:10\n",
            "d_loss:0.1644466890138574\n",
            "g_loss:0.06337123364210129\n",
            "Epoch:38\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16456968570128083\n",
            "g_loss:0.05285685136914253\n",
            "Batch:2\n",
            "d_loss:0.16397970903199166\n",
            "g_loss:0.05838993936777115\n",
            "Batch:3\n",
            "d_loss:0.16440773848444223\n",
            "g_loss:0.05279111489653587\n",
            "Batch:4\n",
            "d_loss:0.1648388376343064\n",
            "g_loss:0.07301672548055649\n",
            "Batch:5\n",
            "d_loss:0.16502410755492747\n",
            "g_loss:0.060949794948101044\n",
            "Batch:6\n",
            "d_loss:0.16432394494768232\n",
            "g_loss:0.058108847588300705\n",
            "Batch:7\n",
            "d_loss:0.1642626210814342\n",
            "g_loss:0.061282675713300705\n",
            "Batch:8\n",
            "d_loss:0.16445584956090897\n",
            "g_loss:0.07496936619281769\n",
            "Batch:9\n",
            "d_loss:0.16452570352703333\n",
            "g_loss:0.06330648064613342\n",
            "Batch:10\n",
            "d_loss:0.16438027221010998\n",
            "g_loss:0.08063443005084991\n",
            "Epoch:39\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16467009880580008\n",
            "g_loss:0.06281104683876038\n",
            "Batch:2\n",
            "d_loss:0.16403971402905881\n",
            "g_loss:0.07098890841007233\n",
            "Batch:3\n",
            "d_loss:0.16426246264018118\n",
            "g_loss:0.06096234917640686\n",
            "Batch:4\n",
            "d_loss:0.16526512888958678\n",
            "g_loss:0.08952786028385162\n",
            "Batch:5\n",
            "d_loss:0.16542617324739695\n",
            "g_loss:0.07582589238882065\n",
            "Batch:6\n",
            "d_loss:0.16432164382422343\n",
            "g_loss:0.07681211829185486\n",
            "Batch:7\n",
            "d_loss:0.1644720259355381\n",
            "g_loss:0.08044321089982986\n",
            "Batch:8\n",
            "d_loss:0.16448568378109485\n",
            "g_loss:0.1017184779047966\n",
            "Batch:9\n",
            "d_loss:0.1646148114814423\n",
            "g_loss:0.07930884510278702\n",
            "Batch:10\n",
            "d_loss:0.16489524306962267\n",
            "g_loss:0.10363670438528061\n",
            "Epoch:40\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.1653098709648475\n",
            "g_loss:0.08448290824890137\n",
            "Batch:2\n",
            "d_loss:0.16430995048722252\n",
            "g_loss:0.10531279444694519\n",
            "Batch:3\n",
            "d_loss:0.16460654570255429\n",
            "g_loss:0.08762794733047485\n",
            "Batch:4\n",
            "d_loss:0.1657219689222984\n",
            "g_loss:0.13222165405750275\n",
            "Batch:5\n",
            "d_loss:0.16615184571128339\n",
            "g_loss:0.10350827872753143\n",
            "Batch:6\n",
            "d_loss:0.16546730347909033\n",
            "g_loss:0.11521033942699432\n",
            "Batch:7\n",
            "d_loss:0.1651265643304214\n",
            "g_loss:0.12734873592853546\n",
            "Batch:8\n",
            "d_loss:0.16540443804115057\n",
            "g_loss:0.1710180789232254\n",
            "Batch:9\n",
            "d_loss:0.16593876003753394\n",
            "g_loss:0.13386735320091248\n",
            "Batch:10\n",
            "d_loss:0.16624504688661546\n",
            "g_loss:0.2055329978466034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:41\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.1667258128290996\n",
            "g_loss:0.14046765863895416\n",
            "Batch:2\n",
            "d_loss:0.16591993113979697\n",
            "g_loss:0.19861482083797455\n",
            "Batch:3\n",
            "d_loss:0.1672219044994563\n",
            "g_loss:0.14540590345859528\n",
            "Batch:4\n",
            "d_loss:0.16773179115261883\n",
            "g_loss:0.271694153547287\n",
            "Batch:5\n",
            "d_loss:0.16959088714793324\n",
            "g_loss:0.16488562524318695\n",
            "Batch:6\n",
            "d_loss:0.16811100905761123\n",
            "g_loss:0.1680111289024353\n",
            "Batch:7\n",
            "d_loss:0.16986217303201556\n",
            "g_loss:0.1304519772529602\n",
            "Batch:8\n",
            "d_loss:0.16773368488065898\n",
            "g_loss:0.1965377777814865\n",
            "Batch:9\n",
            "d_loss:0.17640764731913805\n",
            "g_loss:0.20979174971580505\n",
            "Batch:10\n",
            "d_loss:0.16870515164919198\n",
            "g_loss:0.41513869166374207\n",
            "Epoch:42\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.17589700361713767\n",
            "g_loss:0.12630602717399597\n",
            "Batch:2\n",
            "d_loss:0.17708346771541983\n",
            "g_loss:0.21552221477031708\n",
            "Batch:3\n",
            "d_loss:0.1694242439698428\n",
            "g_loss:0.11279422789812088\n",
            "Batch:4\n",
            "d_loss:0.17155225051101297\n",
            "g_loss:0.1866825520992279\n",
            "Batch:5\n",
            "d_loss:0.17303723632358015\n",
            "g_loss:0.09720276296138763\n",
            "Batch:6\n",
            "d_loss:0.16921213804744184\n",
            "g_loss:0.13623502850532532\n",
            "Batch:7\n",
            "d_loss:0.17407455248758197\n",
            "g_loss:0.17229130864143372\n",
            "Batch:8\n",
            "d_loss:0.16974029992707074\n",
            "g_loss:0.3049953281879425\n",
            "Batch:9\n",
            "d_loss:0.1927180029451847\n",
            "g_loss:0.7374660968780518\n",
            "Batch:10\n",
            "d_loss:0.16832841272844234\n",
            "g_loss:1.346463680267334\n",
            "Epoch:43\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.5892158150672913\n",
            "g_loss:14.858623504638672\n",
            "Batch:2\n",
            "d_loss:2.2003636211156845\n",
            "g_loss:4.987067699432373\n",
            "Batch:3\n",
            "d_loss:1.1662026345729828\n",
            "g_loss:27.967924118041992\n",
            "Batch:4\n",
            "d_loss:0.3989971693008556\n",
            "g_loss:17.10295295715332\n",
            "Batch:5\n",
            "d_loss:0.6392600387334824\n",
            "g_loss:0.0708487406373024\n",
            "Batch:6\n",
            "d_loss:0.3253236934542656\n",
            "g_loss:0.14506055414676666\n",
            "Batch:7\n",
            "d_loss:0.25267006224021316\n",
            "g_loss:0.23837605118751526\n",
            "Batch:8\n",
            "d_loss:0.22553574841003865\n",
            "g_loss:0.21436427533626556\n",
            "Batch:9\n",
            "d_loss:0.20724731567315757\n",
            "g_loss:0.20791752636432648\n",
            "Batch:10\n",
            "d_loss:0.1959489919245243\n",
            "g_loss:0.21306276321411133\n",
            "Epoch:44\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.2010487273801118\n",
            "g_loss:0.1891525685787201\n",
            "Batch:2\n",
            "d_loss:0.1901094880886376\n",
            "g_loss:0.17842638492584229\n",
            "Batch:3\n",
            "d_loss:0.19349515228532255\n",
            "g_loss:0.16567963361740112\n",
            "Batch:4\n",
            "d_loss:0.18656141113024205\n",
            "g_loss:0.20045776665210724\n",
            "Batch:5\n",
            "d_loss:0.182562519563362\n",
            "g_loss:0.16676437854766846\n",
            "Batch:6\n",
            "d_loss:0.18793354893568903\n",
            "g_loss:0.12418660521507263\n",
            "Batch:7\n",
            "d_loss:0.18768933252431452\n",
            "g_loss:0.09921768307685852\n",
            "Batch:8\n",
            "d_loss:0.18129058554768562\n",
            "g_loss:0.10965382307767868\n",
            "Batch:9\n",
            "d_loss:0.17890821653418243\n",
            "g_loss:0.11210960149765015\n",
            "Batch:10\n",
            "d_loss:0.17658917175140232\n",
            "g_loss:0.12591642141342163\n",
            "Epoch:45\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.17931108688935637\n",
            "g_loss:0.09566982090473175\n",
            "Batch:2\n",
            "d_loss:0.17455050360877067\n",
            "g_loss:0.0904010459780693\n",
            "Batch:3\n",
            "d_loss:0.17802371480502188\n",
            "g_loss:0.06945417076349258\n",
            "Batch:4\n",
            "d_loss:0.17783375398721546\n",
            "g_loss:0.08627929538488388\n",
            "Batch:5\n",
            "d_loss:0.17308895324822515\n",
            "g_loss:0.08456861227750778\n",
            "Batch:6\n",
            "d_loss:0.1764911093050614\n",
            "g_loss:0.06934184581041336\n",
            "Batch:7\n",
            "d_loss:0.1765801862347871\n",
            "g_loss:0.05834926664829254\n",
            "Batch:8\n",
            "d_loss:0.17493504961021245\n",
            "g_loss:0.07115573436021805\n",
            "Batch:9\n",
            "d_loss:0.17171897256048396\n",
            "g_loss:0.07159009575843811\n",
            "Batch:10\n",
            "d_loss:0.17185220698593184\n",
            "g_loss:0.0866454541683197\n",
            "Epoch:46\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.1733663205523044\n",
            "g_loss:0.07090428471565247\n",
            "Batch:2\n",
            "d_loss:0.17020389484241605\n",
            "g_loss:0.07026788592338562\n",
            "Batch:3\n",
            "d_loss:0.17271002591587603\n",
            "g_loss:0.06144217774271965\n",
            "Batch:4\n",
            "d_loss:0.17426867072936147\n",
            "g_loss:0.07771921902894974\n",
            "Batch:5\n",
            "d_loss:0.16925099265063182\n",
            "g_loss:0.08143199980258942\n",
            "Batch:6\n",
            "d_loss:0.1719720489345491\n",
            "g_loss:0.06742379814386368\n",
            "Batch:7\n",
            "d_loss:0.17255908553488553\n",
            "g_loss:0.056286606937646866\n",
            "Batch:8\n",
            "d_loss:0.17178156948648393\n",
            "g_loss:0.06866101920604706\n",
            "Batch:9\n",
            "d_loss:0.16901167936157435\n",
            "g_loss:0.06697697937488556\n",
            "Batch:10\n",
            "d_loss:0.16974610000033863\n",
            "g_loss:0.0797465369105339\n",
            "Epoch:47\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.17062221909873188\n",
            "g_loss:0.06997671723365784\n",
            "Batch:2\n",
            "d_loss:0.1679536533774808\n",
            "g_loss:0.06752758473157883\n",
            "Batch:3\n",
            "d_loss:0.17007977020693943\n",
            "g_loss:0.06115402653813362\n",
            "Batch:4\n",
            "d_loss:0.17226825305260718\n",
            "g_loss:0.07308664917945862\n",
            "Batch:5\n",
            "d_loss:0.16769596590893343\n",
            "g_loss:0.07915538549423218\n",
            "Batch:6\n",
            "d_loss:0.1696035541826859\n",
            "g_loss:0.06713607162237167\n",
            "Batch:7\n",
            "d_loss:0.17026487365365028\n",
            "g_loss:0.05779290944337845\n",
            "Batch:8\n",
            "d_loss:0.17015915823867545\n",
            "g_loss:0.06480313837528229\n",
            "Batch:9\n",
            "d_loss:0.16760156402597204\n",
            "g_loss:0.07023532688617706\n",
            "Batch:10\n",
            "d_loss:0.16870679351268336\n",
            "g_loss:0.08075855672359467\n",
            "Epoch:48\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16924589429982007\n",
            "g_loss:0.07712307572364807\n",
            "Batch:2\n",
            "d_loss:0.16677783901104704\n",
            "g_loss:0.07556455582380295\n",
            "Batch:3\n",
            "d_loss:0.1684628403163515\n",
            "g_loss:0.06520300358533859\n",
            "Batch:4\n",
            "d_loss:0.17106413561850786\n",
            "g_loss:0.07553654164075851\n",
            "Batch:5\n",
            "d_loss:0.16677790909307078\n",
            "g_loss:0.08715316653251648\n",
            "Batch:6\n",
            "d_loss:0.16821644053561613\n",
            "g_loss:0.07164786010980606\n",
            "Batch:7\n",
            "d_loss:0.1687717520399019\n",
            "g_loss:0.05909016355872154\n",
            "Batch:8\n",
            "d_loss:0.1690393250901252\n",
            "g_loss:0.06988298892974854\n",
            "Batch:9\n",
            "d_loss:0.16670843947213143\n",
            "g_loss:0.07453960925340652\n",
            "Batch:10\n",
            "d_loss:0.16786061093444005\n",
            "g_loss:0.08790860325098038\n",
            "Epoch:49\n",
            "Number of batches: 10\n",
            "Batch:1\n",
            "d_loss:0.16806960880057886\n",
            "g_loss:0.0804339274764061\n",
            "Batch:2\n",
            "d_loss:0.1660212282440625\n",
            "g_loss:0.07848912477493286\n",
            "Batch:3\n",
            "d_loss:0.16749357496155426\n",
            "g_loss:0.06946712732315063\n",
            "Batch:4\n",
            "d_loss:0.17014794325223193\n",
            "g_loss:0.08187780529260635\n",
            "Batch:5\n",
            "d_loss:0.16597996995551512\n",
            "g_loss:0.09055885672569275\n",
            "Batch:6\n",
            "d_loss:0.16732566128484905\n",
            "g_loss:0.076258085668087\n",
            "Batch:7\n",
            "d_loss:0.16776588116772473\n",
            "g_loss:0.06466784328222275\n",
            "Batch:8\n",
            "d_loss:0.16829284554114565\n",
            "g_loss:0.07052300870418549\n",
            "Batch:9\n",
            "d_loss:0.1660194348078221\n",
            "g_loss:0.07791340351104736\n",
            "Batch:10\n",
            "d_loss:0.16736551013309509\n",
            "g_loss:0.09128475934267044\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.ops.numpy_ops.np_array_ops import reshape\n",
        "if __name__ == '__main__':\n",
        "    # Define hyperparameters\n",
        "    data_dir = \"data\"\n",
        "    # data_dir = \"DataPoints\"\n",
        "    # wiki_dir = os.path.join(data_dir, \"wiki_crop\")\n",
        "    wiki_dir = \"./wiki_crop\"\n",
        "    epochs = 50\n",
        "    batch_size = 1000\n",
        "    image_shape = (64, 64, 3)\n",
        "    z_shape = 100\n",
        "    TRAIN_GAN = True\n",
        "    TRAIN_ENCODER = False\n",
        "    TRAIN_GAN_WITH_FR = False\n",
        "    fr_image_shape = (192, 192, 3)\n",
        "\n",
        "    # Define optimizers\n",
        "    dis_optimizer = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
        "    gen_optimizer = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
        "    adversarial_optimizer = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
        "\n",
        "    \"\"\"\n",
        "    Build and compile networks\n",
        "    \"\"\"\n",
        "    # Build and compile the discriminator network\n",
        "    discriminator = build_discriminator()\n",
        "    discriminator.compile(loss=['binary_crossentropy'], optimizer=dis_optimizer)\n",
        "\n",
        "    # Build and compile the generator network\n",
        "    generator = build_generator()\n",
        "    generator.compile(loss=['binary_crossentropy'], optimizer=gen_optimizer)\n",
        "\n",
        "    # Build and compile the adversarial model\n",
        "    discriminator.trainable = False\n",
        "    input_z_noise = Input(shape=(100,))\n",
        "    input_label = Input(shape=(6,))\n",
        "    recons_images = generator([input_z_noise, input_label])\n",
        "    valid = discriminator([recons_images, input_label])\n",
        "    adversarial_model = Model(inputs=[input_z_noise, input_label], outputs=[valid])\n",
        "    adversarial_model.compile(loss=['binary_crossentropy'], optimizer=gen_optimizer)\n",
        "\n",
        "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time.time()))\n",
        "    tensorboard.set_model(generator)\n",
        "    tensorboard.set_model(discriminator)\n",
        "\n",
        "    \"\"\"\n",
        "    Load the dataset\n",
        "    \"\"\"\n",
        "    images, age_list = load_data(wiki_dir=wiki_dir, dataset=\"wiki\")\n",
        "    age_cat = age_to_category(age_list)\n",
        "    final_age_cat = np.reshape(np.array(age_cat), [len(age_cat), 1])\n",
        "    classes = len(set(age_cat))\n",
        "    y = to_categorical(final_age_cat, num_classes=len(set(age_cat)))\n",
        "\n",
        "    loaded_images = load_images(wiki_dir, images[:10000], (image_shape[0], image_shape[1]))\n",
        "\n",
        "    # Implement label smoothing\n",
        "    real_labels = np.ones((batch_size, 1), dtype=np.float32) * 0.9\n",
        "    fake_labels = np.zeros((batch_size, 1), dtype=np.float32) * 0.1\n",
        "\n",
        "    \"\"\"\n",
        "    Train the generator and the discriminator network\n",
        "    \"\"\"\n",
        "    if TRAIN_GAN:\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch:{}\".format(epoch))\n",
        "\n",
        "            gen_losses = []\n",
        "            dis_losses = []\n",
        "\n",
        "            number_of_batches = int(len(loaded_images) / batch_size)\n",
        "            print(\"Number of batches:\", number_of_batches)\n",
        "            for index in range(number_of_batches):\n",
        "                print(\"Batch:{}\".format(index + 1))\n",
        "\n",
        "                images_batch = loaded_images[index * batch_size:(index + 1) * batch_size]\n",
        "                images_batch = images_batch / 127.5 - 1.0\n",
        "                images_batch = images_batch.astype(np.float32)\n",
        "\n",
        "                y_batch = y[index * batch_size:(index + 1) * batch_size]\n",
        "                z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "\n",
        "                \"\"\"\n",
        "                Train the discriminator network\n",
        "                \"\"\"\n",
        "\n",
        "                # Generate fake images\n",
        "                initial_recon_images = generator.predict_on_batch([z_noise, y_batch])\n",
        "\n",
        "                d_loss_real = discriminator.train_on_batch([images_batch, y_batch], real_labels)\n",
        "                d_loss_fake = discriminator.train_on_batch([initial_recon_images, y_batch], fake_labels)\n",
        "\n",
        "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "                print(\"d_loss:{}\".format(d_loss))\n",
        "\n",
        "                \"\"\"\n",
        "                Train the generator network\n",
        "                \"\"\"\n",
        "\n",
        "                z_noise2 = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "                random_labels = np.random.randint(0, 6, batch_size).reshape(-1, 1)\n",
        "                random_labels = to_categorical(random_labels, 6)\n",
        "                g_loss = adversarial_model.train_on_batch([z_noise2,random_labels],np.asarray([1] * batch_size))\n",
        "\n",
        "                print(\"g_loss:{}\".format(g_loss))\n",
        "\n",
        "                gen_losses.append(g_loss)\n",
        "                dis_losses.append(d_loss)\n",
        "\n",
        "            # Write losses to Tensorboard\n",
        "            # write_log(tensorboard, 'g_loss', np.mean(gen_losses), epoch)\n",
        "            # write_log(tensorboard, 'd_loss', np.mean(dis_losses), epoch)\n",
        "\n",
        "            \"\"\"\n",
        "            Generate images after every 10th epoch\n",
        "            \"\"\"\n",
        "            if epoch % 10 == 0:\n",
        "                images_batch = loaded_images[0:batch_size]\n",
        "                images_batch = images_batch / 127.5 - 1.0\n",
        "                images_batch = images_batch.astype(np.float32)\n",
        "\n",
        "                y_batch = y[0:batch_size]\n",
        "                z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "\n",
        "                gen_images = generator.predict_on_batch([z_noise, y_batch])\n",
        "\n",
        "                for i, img in enumerate(gen_images[:5]):\n",
        "                    save_rgb_img(img, path=\"./results/img_{}_{}.png\".format(epoch, i))\n",
        "\n",
        "        # Save networks\n",
        "        try:\n",
        "            generator.save_weights(\"generator.h5\")\n",
        "            discriminator.save_weights(\"discriminator.h5\")\n",
        "        except Exception as e:\n",
        "            print(\"Error:\", e)\n",
        "\n",
        "    \"\"\"\n",
        "    Train encoder\n",
        "    \"\"\"\n",
        "\n",
        "    if TRAIN_ENCODER:\n",
        "        # Build and compile encoder\n",
        "        encoder = build_encoder()\n",
        "        encoder.compile(loss=euclidean_distance_loss, optimizer='adam')\n",
        "\n",
        "        # Load the generator network's weights\n",
        "        try:\n",
        "            generator.load_weights(\"generator.h5\")\n",
        "        except Exception as e:\n",
        "            print(\"Error:\", e)\n",
        "\n",
        "        z_i = np.random.normal(0, 1, size=(5000, z_shape))\n",
        "\n",
        "        y = np.random.randint(low=0, high=6, size=(5000,), dtype=np.int64)\n",
        "        num_classes = len(set(y))\n",
        "        y = np.reshape(np.array(y), [len(y), 1])\n",
        "        y = to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch:\", epoch)\n",
        "\n",
        "            encoder_losses = []\n",
        "\n",
        "            number_of_batches = int(z_i.shape[0] / batch_size)\n",
        "            print(\"Number of batches:\", number_of_batches)\n",
        "            for index in range(number_of_batches):\n",
        "                print(\"Batch:\", index + 1)\n",
        "\n",
        "                z_batch = z_i[index * batch_size:(index + 1) * batch_size]\n",
        "                y_batch = y[index * batch_size:(index + 1) * batch_size]\n",
        "\n",
        "                generated_images = generator.predict_on_batch([z_batch, y_batch])\n",
        "\n",
        "                # Train the encoder model\n",
        "                encoder_loss = encoder.train_on_batch(generated_images, z_batch)\n",
        "                print(\"Encoder loss:\", encoder_loss)\n",
        "\n",
        "                encoder_losses.append(encoder_loss)\n",
        "\n",
        "            # Write the encoder loss to Tensorboard\n",
        "            write_log(tensorboard, \"encoder_loss\", np.mean(encoder_losses), epoch)\n",
        "\n",
        "        # Save the encoder model\n",
        "        encoder.save_weights(\"encoder.h5\")\n",
        "\n",
        "    \"\"\"\n",
        "    Optimize the encoder and the generator network\n",
        "    \"\"\"\n",
        "    if TRAIN_GAN_WITH_FR:\n",
        "\n",
        "        # Load the encoder network\n",
        "        encoder = build_encoder()\n",
        "        encoder.load_weights(\"encoder.h5\")\n",
        "\n",
        "        # Load the generator network\n",
        "        generator.load_weights(\"generator.h5\")\n",
        "\n",
        "        image_resizer = build_image_resizer()\n",
        "        image_resizer.compile(loss=['binary_crossentropy'], optimizer='adam')\n",
        "\n",
        "        # Face recognition model\n",
        "        fr_model = build_fr_model(input_shape=fr_image_shape)\n",
        "        fr_model.compile(loss=['binary_crossentropy'], optimizer=\"adam\")\n",
        "\n",
        "        # Make the face recognition network as non-trainable\n",
        "        fr_model.trainable = False\n",
        "\n",
        "        # Input layers\n",
        "        input_image = Input(shape=(64, 64, 3))\n",
        "        input_label = Input(shape=(6,))\n",
        "\n",
        "        # Use the encoder and the generator network\n",
        "        latent0 = encoder(input_image)\n",
        "        gen_images = generator([latent0, input_label])\n",
        "\n",
        "        # Resize images to the desired shape\n",
        "        resized_images = Lambda(lambda x: K.resize_images(gen_images, height_factor=3, width_factor=3,\n",
        "                                                          data_format='channels_last'))(gen_images)\n",
        "        embeddings = fr_model(resized_images)\n",
        "\n",
        "        # Create a Keras model and specify the inputs and outputs for the network\n",
        "        fr_adversarial_model = Model(inputs=[input_image, input_label], outputs=[embeddings])\n",
        "\n",
        "        # Compile the model\n",
        "        fr_adversarial_model.compile(loss=euclidean_distance_loss, optimizer=adversarial_optimizer)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch:\", epoch)\n",
        "\n",
        "            reconstruction_losses = []\n",
        "\n",
        "            number_of_batches = int(len(loaded_images) / batch_size)\n",
        "            print(\"Number of batches:\", number_of_batches)\n",
        "            for index in range(number_of_batches):\n",
        "                print(\"Batch:\", index + 1)\n",
        "\n",
        "                images_batch = loaded_images[index * batch_size:(index + 1) * batch_size]\n",
        "                images_batch = images_batch / 127.5 - 1.0\n",
        "                images_batch = images_batch.astype(np.float32)\n",
        "\n",
        "                y_batch = y[index * batch_size:(index + 1) * batch_size]\n",
        "\n",
        "                images_batch_resized = image_resizer.predict_on_batch(images_batch)\n",
        "\n",
        "                real_embeddings = fr_model.predict_on_batch(images_batch_resized)\n",
        "\n",
        "                reconstruction_loss = fr_adversarial_model.train_on_batch([images_batch, y_batch], real_embeddings)\n",
        "\n",
        "                print(\"Reconstruction loss:\", reconstruction_loss)\n",
        "\n",
        "                reconstruction_losses.append(reconstruction_loss)\n",
        "\n",
        "            # Write the reconstruction loss to Tensorboard\n",
        "            write_log(tensorboard, \"reconstruction_loss\", np.mean(reconstruction_losses), epoch)\n",
        "\n",
        "            \"\"\"\n",
        "            Generate images\n",
        "            \"\"\"\n",
        "            if epoch % 10 == 0:\n",
        "                images_batch = loaded_images[0:batch_size]\n",
        "                images_batch = images_batch / 127.5 - 1.0\n",
        "                images_batch = images_batch.astype(np.float32)\n",
        "\n",
        "                y_batch = y[0:batch_size]\n",
        "                z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "\n",
        "                gen_images = generator.predict_on_batch([z_noise, y_batch])\n",
        "\n",
        "                # for i, img in enumerate(gen_images[:5]):\n",
        "                #     save_rgb_img(img, path=\"results/img_opt_{}_{}.png\".format(epoch, i))\n",
        "\n",
        "        # Save improved weights for both of the networks\n",
        "        generator.save_weights(\"generator_optimized.h5\")\n",
        "        encoder.save_weights(\"encoder_optimized.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtSp-s_X1foZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4Zo78OR-Mn1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}